2025-12-02 17:09:44,037 - easytorch-training - INFO - Initializing training.
2025-12-02 17:09:44,038 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 3.0}
2025-12-02 17:09:44,038 - easytorch-training - INFO - Building training data loader.
2025-12-02 17:09:44,098 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.002
    maximize: False
    weight_decay: 1e-05
)
2025-12-02 17:09:44,098 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fb3af947ac0>
2025-12-02 17:09:44,102 - easytorch-training - INFO - Initializing validation.
2025-12-02 17:09:44,102 - easytorch-training - INFO - Building val data loader.
2025-12-02 17:09:44,213 - easytorch-training - INFO - Epoch 1 / 100
2025-12-02 17:09:45,797 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/site-packages/easytorch/launcher/launcher.py", line 30, in training_func
    runner.train(cfg)
  File "/root/miniconda3/lib/python3.10/site-packages/easytorch/core/runner.py", line 351, in train
    loss = self.train_iters(epoch, iter_index, data)
  File "/root/autodl-tmp/code/STD-MAE/basicts/runners/base_tsf_runner.py", line 237, in train_iters
    forward_return = list(self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True))
  File "/root/autodl-tmp/code/STD-MAE/stdmae/stdmae_runner/stdmae_runner.py", line 66, in forward
    prediction= self.model(history_data=history_data, long_history_data=long_history_data, future_data=None, batch_seen=iter_num, epoch=epoch)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/autodl-tmp/code/STD-MAE/stdmae/stdmae_arch/stdmae_perio.py", line 58, in forward
    hidden_states_t = self.tmae(short_term_history)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/autodl-tmp/code/STD-MAE/stdmae/stdmae_arch/mask/TQpretrain.py", line 88, in forward
    for layer in self.encoder:
TypeError: 'MultiheadAttention' object is not iterable

